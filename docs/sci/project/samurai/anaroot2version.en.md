# ANAROOT Detailed Documentation

## Abstract

This report aims to provide RIKEN RIBF users with a comprehensive English guide to the ANAROOT software framework. ANAROOT is the core tool for both online and offline data analysis in RIBF experiments, developed on top of ROOT. This document starts from the basics of ANAROOT and its installation/configuration, and gradually delves into its core concepts, data processing workflow, and script development.

In particular, this document focuses on how to use ANAROOT to analyze data from drift chambers (DC, also referred to as Proton Drift Chambers, PDC) and NEBULA neutron detectors in SAMURAI experiments, covering key steps such as calibration, track reconstruction, and neutron identification. The document also clarifies previous misunderstandings where BigRIPS focal plane PPACs were confused with PDCs, and details the differences in their functions and data analysis methods in experiments.

With this guide, users are expected to grow from ANAROOT beginners to proficient analysts capable of independently performing complex data analyses.

**Keywords:** ANAROOT, RIKEN, RIBF, SAMURAI, PDC, DC, NEBULA, ROOT, data analysis, nuclear physics experiment

---

## Part I: ANAROOT Basics

### 1. Introduction to ANAROOT

#### 1.1 What is ANAROOT?

ANAROOT is a toolkit based on the ROOT framework, designed specifically for online and offline data analysis in experiments at the Radioactive Isotope Beam Factory (RIBF) of RIKEN [1]. Developed by the RIBFDAQ team, it is optimized for the RIDF (RIKEN Data Format) raw data generated by the RIBF data acquisition system (Babirl) [2, 3].

As the standard data analysis platform for RIBF experiments, ANAROOT provides dedicated tools for handling RIBF-specific data formats and detector systems, ensuring consistency in analysis. Built on top of ROOT, it allows researchers to leverage ROOT’s extensive data analysis and visualization capabilities.

#### Design Goals and Application Scenarios (RIBF Experiments)

The main goal of ANAROOT is to provide data analysis functionality for nuclear physics experiments at RIBF [2]. It has been widely used in various projects, such as the SAMURAI experiment in April 2024, the EURICA experiment, and many experiments involving the BigRIPS spectrometer [2].

The software supports secondary particle identification using the BigRIPS or ZeroDegree spectrometers and includes reconstruction code for the SAMURAI spectrometer and the EURICA detector array (including event building based on timestamps) [3, 1]. ANAROOT is tailored for the high-intensity, complex experimental environment at RIBF, which often involves multiple detectors and requires sophisticated data processing to accomplish particle identification (PID), tracking, and energy/time measurements. Its ongoing development reflects the evolving needs of these experiments.

The frequent mention of various projects and specific experiment years in ANAROOT’s changelog [2] demonstrates that ANAROOT is a “living” project, with the development team continuously maintaining and adjusting it according to actual research needs. This ensures that users have access to a toolkit that keeps pace with current RIBF experimental requirements. This close integration with experiments guarantees both practicality and state-of-the-art features, as the software is tested and optimized with real experimental data. However, for very new or special configurations, some features or documentation may be less mature compared to long-established setups.

#### 1.2 Relationship between ANAROOT and the ROOT Framework

ANAROOT is deeply integrated with and dependent on the ROOT library. Therefore, ROOT must be properly installed and configured before installing ANAROOT [2]. During initialization, ANAROOT generates ROOT login macros (such as `rootlogon.C` and `.rootrc`) to configure the ROOT environment for loading ANAROOT libraries and settings [2]. Note that ANAROOT development versions are often tied to specific ROOT versions (e.g., some ANAROOT versions are based on ROOT 6.28.04 or ROOT 5.34.21) [2], so users should pay attention to version compatibility.

This tight coupling means that ANAROOT’s functionality is closely linked to ROOT’s capabilities. Users can directly use ROOT’s extensive features, such as graphics, fitting algorithms, and data I/O, within the ANAROOT environment. However, limitations or bugs in specific ROOT versions may affect ANAROOT’s operation. Thus, users with a basic understanding of ROOT will find it easier to get started with ANAROOT and make full use of its advanced features.

#### 1.3 Main Features and Core Components of ANAROOT

ANAROOT provides a complete set of features for RIBF experiment data analysis, covering the entire process from raw data handling to extraction of physical results:

- **RIDF Raw Data Decoding:** The foundation of ANAROOT, capable of parsing RIDF format data produced by the RIBF DAQ system [1].
- **Versatile Data Input Interfaces:** Supports reading data from RIDF files, online shared memory, and data streams, meeting the needs of both offline analysis and online monitoring [1, 4].
- **RIBF Detector Reconstruction Libraries:** Includes reconstruction libraries for major RIBF detector systems, such as BigRIPS (for secondary beam PID), SAMURAI spectrometer (for momentum analysis and neutron detection), and the EURICA array (for gamma-ray detection and timestamp-based event building) [2, 5].
- **Calibration Functions:** Provides calibration modules for specific detectors or physical quantities, such as total kinetic energy (TKE) calibration, SAMURAI-TED (target energy loss detector), and SAMURAI-ICF (ion chamber) calibration [2].
- **Data Processing and Management:** Includes features for extracting run information from RIDF headers, handling RF signals (Plastic class), and managing FADC raw data containers [2].
- **Online Monitoring:** The `AnaLoop` routine is mainly used for online monitoring of data quality and detector status [2].
- **Command-Line User Interface (CUI):** Offers a text-based interactive interface, including an ANAPAW-like command line (implemented via the Nadeko library) and user-customizable `AnaLoop` analysis routines [1].

The mention of an “ANAPAW-like command line” [1] indicates that ANAROOT was designed to provide a smooth transition for users accustomed to PAW (Physics Analysis Workstation), a data analysis software widely used before ROOT, with its own unique command syntax. ANAROOT’s familiar interface lowers the learning curve for physicists with PAW experience, enabling them to adapt quickly, especially for online monitoring or simple interactive analysis tasks. Although ROOT is the underlying core, this feature offers a more intuitive operation mode for some users.

### 2. ANAROOT Installation and Environment Configuration

#### 2.1 Installation Steps on Linux

To install ANAROOT on Linux, first ensure that the ROOT environment is properly installed and configured, then choose the appropriate installation method based on the ANAROOT version.

- **Prerequisite: ROOT Installation and Configuration**

  ANAROOT depends entirely on the ROOT library, so ROOT must be installed first. Users can download the required ROOT version from the official ROOT website (`root.cern.ch`) [2]. After installation, set the ROOT environment variables, usually by executing `$ROOTSYS/bin/thisroot.sh` in the shell, where `$ROOTSYS` points to the ROOT installation path [2].

- **Dependencies**

  Installing ANAROOT (especially v4.5 and earlier) requires several third-party development libraries [2]. These libraries are necessary for compiling and running ANAROOT.

  For ANAROOT v4.5 and earlier, the main dependencies include:

  - `libxml2-devel`: For parsing XML files, as ANAROOT uses XML for parameters and configuration.
  - `automake`: GNU build system tool.
  - `autoconf`: GNU configuration script generator.
  - `libtool`: GNU shared library support script.
  - `libedit`: Provides command-line editing features.

  If you need to use MINOS (a time projection chamber) analysis modules, you also need to install the `minos-fem` library [2]. The explicit mention of `libxml2-devel` highlights the central role of XML in ANAROOT parameter management. Understanding XML structure is beneficial for customizing analysis workflows, as detector parameters, calibration constants, and analysis settings may all be configured via XML files.

- **Obtaining ANAROOT Source Code**

  The official ANAROOT source package is usually released as a `.tgz` archive, available from the RIKEN RIBFDAQ website, e.g., `anaroot_v4.6.1.tgz` or `anaroot_v4.5.40.tgz` [2]. Although platforms like GitHub also provide source archives [6, 7], the RIKEN official release should be considered the authoritative source for ANAROOT.

- **CMake Build (v4.6.1 and Later)**

  For newer versions of ANAROOT (v4.6.1 and later), it is recommended to use CMake for building and installation [2]:

  1.  Extract the source: `tar zxvf anaroot_vX.Y.Z.tgz`
  2.  Enter the source directory: `cd anaroot`
  3.  Create build and install directories: `mkdir build install`
  4.  Enter the build directory: `cd build`
  5.  Run CMake: `cmake -DCMAKE_INSTALL_PREFIX=$PWD/../install ..`
      - Here, `-DCMAKE_INSTALL_PREFIX=$PWD/../install` sets the install path to the `install` folder under the source directory; users can specify another path if needed.
  6.  Build the source: `make`
  7.  Install the software: `make install`

  This CMake-based build is the modern, recommended approach, offering good cross-platform support and flexibility.

- **autogen.sh Configuration (v4.5 and Earlier)**

  For v4.5 and earlier, the installation relies on the autotools build system [2]:

  1.  Extract the source: `tar zxvf anaroot_vX.Y.Z.tgz`
  2.  Enter the source directory: `cd anaroot`
  3.  Run the configuration script: `./autogen.sh --prefix=$PWD [--enable-minos=yes (default is no)]`
      - `--prefix=$PWD` installs ANAROOT in the current directory (creating `lib`, `bin`, `include`, etc.). You can change this to your preferred path.
      - `--enable-minos=yes` is optional, enabling MINOS modules (default is off).
  4.  Build and install: `make install`

- **Table 1: ANAROOT Linux Installation Dependencies**

| Package Name      | Recommended Version/Notes         | Main Purpose                        | Reference |
| :----------------| :-------------------------------- | :----------------------------------- | :-------- |
| ROOT             | >= 5.34 (see dev notes)           | Core analysis framework              | [2]       |
| libxml2-devel    | System version                    | XML parameter file parsing           | [2]       |
| automake         | System version                    | Build system (ANAROOT < v4.6.1)      | [2]       |
| autoconf         | System version                    | Build system (ANAROOT < v4.6.1)      | [2]       |
| libtool          | System version                    | Shared library management            | [2]       |
| libedit          | System version                    | Command-line editing                 | [2]       |
| CMake            | >= (ROOT compatible)              | Build system (ANAROOT >= v4.6.1)     | [2]       |
| minos-fem (opt.) | 1.1.1-minimal                     | MINOS analysis (manual for < v4.6.1) | [2]       |

This table summarizes the dependencies needed before installing ANAROOT, helping users check their system environment in advance and reduce installation issues due to missing dependencies.

#### 2.2 Environment Variable Setup

Proper environment variable configuration is key to ensuring ANAROOT runs correctly. First, make sure ROOT’s environment variables are set, usually by running `source $ROOTSYS/bin/thisroot.sh` [2].

For ANAROOT (especially v4.5 and earlier), after compilation and installation, you may need to manually set `LD_LIBRARY_PATH` so the system can find ANAROOT’s shared libraries, e.g., `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ANAROOT_INSTALL_DIR/lib` (where `$ANAROOT_INSTALL_DIR` is the ANAROOT install path) [2].

More conveniently, ANAROOT usually generates a `setup.sh` (or similar) script in its top-level install directory after installation [2]. Running `source setup.sh` will automatically configure all necessary ANAROOT environment variables. Adding this command to your shell startup file (e.g., `~/.bashrc` or `~/.zshrc`) ensures the ANAROOT environment is ready in every new terminal session. This script greatly simplifies environment setup and avoids errors from manually setting multiple variables.

#### 2.3 Common Installation Issues and Troubleshooting

Some known issues and solutions:

- **v4.5 and earlier, ROOT fails after copying files from another PC:** Try running `make distclean` before `./autogen.sh` to clean previous build files [2].
- **MAC OS X specific issues:**
  - `libtoolize` may not be installed; use `glibtoolize` instead and modify `autogen.sh` accordingly [2].
  - Shared libraries on macOS use `.dylib` extension, but ROOT’s `gSystem->Load("...")` may expect `.so`. Rename or symlink `.dylib` to `.so` [2].
- **Loading `analoop` libraries separately:** If you need to load `analoop` libraries individually, modify `rootlogon.C` to load `libanaloop.so`, `libanaloopexample.so`, and `libanaloopencexample.so` instead of `libanaanaloop.so` [2].

For more complex installation issues, consult ANAROOT’s mailing list (if available), internal RIKEN documentation, or contact the developers (e.g., T. Isobe [3]). Strictly following official steps and ensuring all dependencies are installed is key to avoiding problems.

### 3. Core Concepts and Software Architecture of ANAROOT

* **3.1 Data Processing Workflow: From RIDF to Physical Results** [1, 5]

  ANAROOT follows a typical experimental data analysis workflow, starting from raw data input, through decoding, calibration, and reconstruction, to the final physical analysis by the user.

  - **RIDF Raw Data (Raw Data)**

    The starting point of the analysis is the RIDF format raw data. These data are generated by the Babirl data acquisition system at RIBF and can be stored as offline files or accessed via online shared memory or data streams [1].

  - **Decoding (Decoding) - `TArtEventStore`**

    The raw binary data are not directly interpretable by the user. The `TArtEventStore` class is responsible for reading and decoding RIDF raw data [1]. The decoded data exist as `TArtRawEventObject` objects, containing event information such as run number, event number, timestamp, etc., and an array of `TArtRawSegmentObject` [5, 8]. Each `TArtRawSegmentObject` corresponds to a data segment in the data acquisition system, internally containing a device identifier (e.g., detector ID) and a series of `TArtRawDataObject` [5, 8]. The `TArtRawDataObject` is the most basic data unit, storing the raw measurement values (e.g., ADC, TDC values) of a single channel.

    Users can open RIDF files or connect to online data sources using `TArtEventStore::Open()` method [1, 4], and iterate through events using `TArtEventStore::GetNextEvent()`. If a mapping file is used (loaded via `TArtEventStore::LoadMapConfig()`), users can also obtain identifier information related to detector channels in an ANAPAW-like manner using methods such as `GetCategoryID()`, `GetDetectorID()`, and `GetDatatypeID()` of `TArtRawDataObject` [5, 8].

  - **Calibration (Calibration) - `TArtCalibXXX` series classes**

    The decoded raw data (e.g., ADC counts, TDC counts) need to be converted into physically meaningful quantities (e.g., energy, time, position). This process is carried out by the `TArtCalibXXX` series of calibration classes [1, 5]. For example, `TArtCalibPPAC` is used to calibrate PPAC detector data, and `TArtCalibPID` is used for overall calibration related to particle identification [1]. For detectors in the SAMURAI experiment, such as drift chambers (BDC, FDC), plastic scintillator arrays (HODF/P), ion chambers (ICF), and NEBULA neutron detectors, ANAROOT provides corresponding calibration classes (e.g., sub-modules under `TArtCalibSAMURAI` or standalone `TArtCalibNEBULA`, etc.) [5, 8].

  - **Reconstruction (Reconstruction) - `TArtRecoXXX` series classes**

    After calibration, the reconstruction step uses the calibrated data, detector geometry, and physical algorithms to reconstruct the complete information of the physical events [1, 5]. For instance, the `TArtRecoTOF` class is used to reconstruct the time of flight, while SAMURAI drift chamber data are processed by classes like `TArtDCTrack` for track reconstruction, providing information on the trajectory and momentum of charged particles [5, 8].

  - **User Analysis (User Analysis)**

    The final stage is user analysis, where physicists use the reconstructed physical quantities to extract the desired physical results by setting selection criteria (“cuts”), fitting data distributions, and constructing physical models [1]. The `AnaLoop` framework is the main tool for custom analysis.

  The three-step analysis architecture of "decoding -> calibration -> reconstruction" adopted by ANAROOT [5, 8] is a standard paradigm in high-energy and nuclear physics experimental data processing. This modular design clearly separates the tasks of each processing stage, facilitating parallel development and collaborative work, and making code maintenance and debugging easier. Users can intervene at different processing stages according to their needs to obtain the required data objects.

* **3.2 Key Data Structures and Libraries** [5, 8]

  ANAROOT provides a series of core classes to organize and manage the data flow.

  - **`TArtStoreManager`:**

    This class is the "nerve center" of data and parameter management in ANAROOT [5, 8]. It is responsible for managing the input and output of various data containers and the access to analysis parameters. All data containers (usually `TClonesArray` objects, which are standard classes in ROOT for efficiently storing collections of similar objects) are registered with the `TArtStoreManager` after creation, and user analysis code can access pointers to specific data containers through its provided interfaces (e.g., `FindDataContainer<Type>("name")`) [5, 8]. Detailed functionality can be found in the `TArtStoreManager.hh` header file. It can be considered a singleton or global access point, providing user code with a unified and convenient way to access all raw data, calibrated data, and reconstruction results of detectors in the current event, as well as global analysis parameters. This greatly simplifies the cumbersome task of passing a large number of data object pointers in complex analysis code.

  - **`TArtRawDataObject`, `TArtRawSegmentObject`, `TArtRawEventObject`:**

    These three classes constitute the low-level access interface to the decoded raw data [5, 8]. `TArtRawEventObject` encapsulates the raw information of a complete event, including run number, event number, timestamp, and an array of `TArtRawSegmentObject`. Each `TArtRawSegmentObject` corresponds to a data segment in the DAQ system, containing device ID (e.g., detector number) and a set of `TArtRawDataObject`. `TArtRawDataObject` is the smallest data unit, storing the raw values of a single electronic channel (e.g., ADC or TDC values). Detailed data format definitions can be found in the Dataformat section of the RIBF DAQ manual [5, 8]. Understanding the structure of these classes is crucial for low-level data validation or developing new decoding/calibration modules.

  - **Detector Data Containers (e.g., `TArtPPAC`, `TArtDCHit`, `TArtDCTrack`, `TArtNEBULAPla`):**

    ANAROOT defines dedicated data container classes for various detectors and physical quantities, used to store calibrated or reconstructed information. These containers are usually managed by `TArtStoreManager` in the form of `TClonesArray` [5, 8].

    For example:

    - Related to BigRIPS: `TArtPPAC` (Parallel Plate Avalanche Counter data), `TArtIC` (ion chamber data), `TArtPlastic` (plastic scintillator data), `TArtFocalPlane` (focal plane parameters), `TArtTOF` (time of flight), `TArtRIPS` (RIPS parameters), `TArtBeam` (beam parameters).
    - Related to SAMURAI: `TArtDCHit` (drift chamber hit information), `TArtDCTrack` (drift chamber reconstructed tracks), `TArtHODPla` (HODOSCOPE plastic strip data), `TArtICF` (SAMURAI ion chamber data), `TArtNEBULAPla` (NEBULA plastic scintillator data), `TArtNEBULAHPC` (NEBULA high-purity germanium detector data, if the NEBULA configuration includes germanium detectors for gamma-ray detection, this item is relevant; for pure neutron analysis, focus on `TArtNEBULAPla`).
    - Related to DALI: `TArtDALINaI` (DALI2 NaI(Tl) detector data).
    - General event information: `TArtEventInfo` (event number, trigger bits, timestamp, etc.).

    When analyzing specific detector data, users need to obtain the corresponding data container of these types from `TArtStoreManager`.

* **3.3 Parameter Management: Use of XML Files** [1, 8, 9]

  ANAROOT extensively uses XML (Extensible Markup Language) files to manage various parameters in experiments, such as detector geometry, calibration constants, analysis thresholds (cut parameters), etc. [5, 8]. This practice separates parameter configuration from the analysis code itself, allowing parameter modifications without recompiling the code, greatly enhancing the flexibility and efficiency of analysis work.

  ANAROOT provides classes like `TArtBigRIPSParameters` and `TArtSAMURAIParameters` to load and manage parameters for specific subsystems (e.g., BigRIPS or SAMURAI) [1, 9]. These parameter classes typically contain a method like `LoadParameter(const char* xmlfilename)` to read parameter configurations from specified XML files, e.g., `setup->LoadParameter("db/BigRIPSPPAC.xml")` [1].

  Additionally, more general parameter classes like `TArtUserParameters` are proposed for handling global or user-defined parameters not specific to any large detector system [9].

  The structure of XML files usually contains a series of parameter entries, each with tags like parameter name (NAME), value (val), and type (type) [9]. For example, a parameter defining the offset of a PPAC position might be represented in XML as:

  ```xml
  <parameter>
      <NAME>F3PPAC1A_X_OFFSET</NAME>
      <val>0.123</val>
      <type>Double_t</type>
  </parameter>
  ```

  This structured parameter management approach, especially with the introduction of dedicated parameter classes like `TArtUserParameters` and `TArtSAMURAIParameters`, indicates that ANAROOT adopts an organized method for parameter handling. Users need to understand the XML file format corresponding to the detectors or parameter sets involved in their analysis to correctly configure or modify experimental parameters. Once loaded, these parameters are usually registered with `TArtStoreManager` for subsequent calibration and reconstruction modules.

- **Table 2: Core Key Classes of ANAROOT and Their Functions**

| Class Name         | Main Function                        | Key Methods/Notes                                                                                                                                                                                                                       | Relevant Snippets |
| :----------------- | :----------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------- |
| `TArtStoreManager` | Central manager for data and parameters | `FindDataContainer<Type>("name")`, `FindParameter("name")`, `Register`                                                                                                                                                                | [5, 8]            |
| `TArtEventStore`  | RIDF data decoding and event loop control | `Open()`, `GetNextEvent()`, `LoadMapConfig()`, `ClearData()`                                                                                                                                                                         | [1, 5, 4, 8]      |
| `TArtRawEventObject` | Stores decoded raw data of the entire event | Provides access to `TArtRawSegmentObject`                                                                                                                                                                                                | [5, 8]            |
| `TArtRawSegmentObject` | Stores raw data of specific device segments | Provides access to `TArtRawDataObject`, `GetDevice()`, `GetFP()`, `GetDetector()`                                                                                                                                                     | [5, 8]            |
| `TArtRawDataObject` | Stores the lowest level raw data unit | `GetValue()`, `GetCategoryID()`, `GetDetectorID()`, `GetDatatypeID()`                                                                                                                                                                | [5, 8]            |
| `TArtCalibXXX`    | Base class or specific implementation of calibration classes | E.g.: `TArtCalibPID`, `TArtCalibPPAC`, `TArtCalibSAMURAI` (includes calibration for various SAMURAI sub-detectors), `ReconstructData()` (calibration logic is usually executed here)                                                  | [1, 5, 8]         |
| `TArtRecoXXX`     | Base class or specific implementation of reconstruction classes | E.g.: `TArtRecoTOF`, `TArtRecoPID`, `ReconstructData()` (reconstruction logic is usually executed here)                                                                                                                                 | [1, 5, 8]         |
| `TArtAnaLoop`     | Base class for user analysis loop   | `Construct()`, `Calculate()`, `Destruct()`, `ClassName()`                                                                                                                                                                            | [1, 10, 4]        |
| `TArtBigRIPSParameters` | BigRIPS parameter management         | `LoadParameter("xmlfile")`, `FindPara(char* name)`                                                                                                                                                                                   | [1]                |
| `TArtSAMURAIParameters` | SAMURAI parameter management         | `LoadParameter("xmlfile")`, `ParseCalibBeamPara(TXMLNode*)` (example)                                                                                                                                                               | [9]                |
| `TArtPPAC`        | PPAC detector data container        | `GetX()`, `GetY()`, `GetTSumX()`, `GetTSumY()`, `GetTX1()`, `GetTX2()`, `GetTY1()`, `GetTY2()`, `GetTA()`                                                                                                                                 | [1, 5, 8]         |
| `TArtDCHit`       | SAMURAI drift chamber hit data container | `GetTDC()`, `GetDriftLength()`, `GetWireID()`, `GetLayer()`                                                                                                                                                                        | [5, 8] (inferred) |
| `TArtDCTrack`     | SAMURAI drift chamber reconstructed track data container | `GetPositionX()`, `GetPositionY()`, `GetAngleX()`, `GetAngleY()`, `GetChi2()`, `GetMomentum()` (or calculated via Bρ)                                                                                                               | [5, 8] (inferred) |
| `TArtNEBULAPla`   | NEBULA plastic scintillator data container | `GetID()`, `GetTDC(pmt_id)`, `GetQDC(pmt_id)`, `GetTime()`, `GetQ()`, `GetPosition()` (calculated), `GetTOF()` (calculated)                                                                                                        | [5, 8] (partially inferred) |

This table provides users with a quick reference to the core classes of ANAROOT, helping them understand the overall architecture of the software and the roles and functions of each component in the data analysis workflow. For beginners, familiarizing themselves with these key classes is fundamental to effectively navigating and using the ANAROOT framework.

---

## Part II: Practical Data Analysis with ANAROOT

### 4. Important Clarification: BigRIPS PPACs vs SAMURAI PDCs

Before delving into the data analysis of SAMURAI experiments, it is essential to clarify a potential point of confusion: the Parallel Plate Avalanche Counters (PPACs) in the BigRIPS spectrometer and the Drift Chambers (DCs, referred to by users as Proton Drift Chambers, PDCs) used for charged particle tracking in SAMURAI experiments are different detectors with distinct functions and applications.

#### 4.1 BigRIPS PPACs: Functions and Data Characteristics

BigRIPS is a large secondary beam separator and spectrometer located upstream of the SAMURAI spectrometer [11]. PPAC detectors are installed at various focal plane positions (e.g., F3, F5, F7) [1, 11]. The primary function of these PPACs is to precisely measure the two-dimensional position (X, Y coordinates) and timing information of each particle in the secondary radioactive isotope beam passing through BigRIPS [1]. By combining time-of-flight (TOF) measurements between different focal planes and magnetic field settings, the magnetic rigidity (Bρ) of the secondary beam particles can be accurately determined [11]. The TOF-Bρ-ΔE (energy loss, typically measured by the ion chamber IC) method enables the identification of different nuclides in the secondary beam, i.e., determining their atomic number Z and mass-to-charge ratio A/Q [1, 5].

In ANAROOT, the classes related to BigRIPS PPAC data processing mainly include `TArtPPAC` (stores calibrated data of individual PPACs, such as position, time, etc.), `TArtCalibPPAC` (responsible for PPAC raw data calibration), and `TArtFocalPlane` (stores reconstruction parameters of the focal plane) [1, 8]. The related calibration and geometry parameters are usually stored in XML files, such as `BigRIPSPPAC.xml` and `FocalPlane.xml` [1].

Thus, the PPACs in BigRIPS are crucial detectors for characterizing and identifying the incident beam particles entering the SAMURAI experimental target area.

#### 4.2 SAMURAI PDC (Drift Chambers):

SAMURAI (Superconducting Analyzer for Multi-particles from Radioisotope beams) is a spectrometer with a superconducting magnet designed to study nuclear reactions induced by radioactive isotope beams and simultaneously measure multiple reaction products [12, 13]. The "Proton Drift Chambers (PDC)" mentioned by users actually refer to the drift chambers (DCs) deployed in the SAMURAI experimental setup. These drift chambers, such as the BDC (Beam Drift Chamber, located before the target to measure the incident beam's position and angle at the target) and FDC (Forward Drift Chamber, located after the SAMURAI superconducting magnet to measure the tracks of charged reaction products, especially protons) [5, 8], are core components of the SAMURAI detector system.

The main function of these drift chambers is to precisely measure the trajectories of charged particles (such as protons, deuterons, or other heavy ion fragments) produced in nuclear reactions within or just after the SAMURAI magnetic field. By analyzing the curvature of the particles in the magnetic field, their momenta can be reconstructed [12, 13]. This is crucial for studying nuclear structure, reaction mechanisms, and astrophysical nuclear processes.

#### 4.3 PDC & SPPAC

1.  **Detector Technology Principles:**
    - **PPACs (Parallel Plate Avalanche Counters):** A type of gas detector designed to provide fast timing response and good two-dimensional position resolution, relying on gas avalanche between parallel electrode plates to amplify the signal.
    - **DCs (Drift Chambers):** A more complex gas detector designed to achieve high-precision three-dimensional track point reconstruction by precisely measuring the drift time of ionization electrons to the anode wire in a specific electric field. This typically requires more refined electrode structures and gas controls.
2.  **Location and Core Functions:**
    - **BigRIPS PPACs:** Installed upstream in the SAMURAI target area, part of the BigRIPS secondary beam separator. Their core function is to provide precise identification (via TOF-Bρ-ΔE method) and initial kinematic parameters (such as position, angle) for each beam particle entering the SAMURAI target area.
    - **SAMURAI DCs (PDCs):** Installed around the SAMURAI target area and downstream of the SAMURAI superconducting magnet. Their core function is to track the emitted charged particles from the target and precisely reconstruct their momenta through the curvature in the magnetic field.
3.  **ANAROOT Processing Classes:**
    - Data from BigRIPS PPACs are processed by classes like `TArtPPAC`, `TArtCalibPPAC`, etc.
    - Data from SAMURAI DCs are processed by classes like `TArtDCHit`, `TArtDCTrack`, `TArtCalibDC` (or more specific ones like `TArtCalibBDC`, `TArtCalibFDC`), etc.


### 5. Using ANAROOT to Analyze SAMURAI PDC (Drift Chamber) Data

This section will detail how to use ANAROOT to analyze data from the drift chambers (DCs, referred to as PDCs by users) in the SAMURAI experiment. The drift chambers play a key role in tracking charged reaction products (especially protons) in SAMURAI experiments, allowing for momentum reconstruction of these products by precisely measuring their trajectories in conjunction with the magnetic field information of the SAMURAI superconducting magnet.

#### 5.1 Introduction to SAMURAI PDC Detectors

The SAMURAI spectrometer is equipped with multiple drift chambers to precisely measure the tracks of charged particles at different locations [12, 13]. The key components of the drift chambers typically include:

- **BDCs (Beam Drift Chambers):** Usually refer to the drift chambers located upstream of the SAMURAI experiment target, used to precisely determine the position and angle of the incident beam particles hitting the target. This is crucial for determining the reaction vertex and the kinematic parameters of the incident particles.
- **FDCs (Forward Drift Chambers):** Usually refer to the drift chambers located downstream of the SAMURAI superconducting magnet, such as FDC0 (possibly inside or just at the magnet entrance), FDC1, FDC2, etc. These detectors measure the tracks of charged reaction products after they have been deflected by the magnetic field. FDC0 may provide information on the particle's entry point into the magnet, while FDC2 measures its position and angle after it has traveled some distance, allowing for precise determination of its curvature in the magnetic field.

These drift chambers are constructed from multiple layers of anode wires and cathode planes arranged in a specific configuration. When a charged particle passes through the drift chamber gas, it ionizes the gas, and the ionization electrons drift towards the nearest anode wire under the influence of an electric field. By measuring the drift time, the distance between the particle's track and the anode wire can be inferred.

#### 5.2 Characteristics of PDC Data and Their Representation in ANAROOT

In ANAROOT, the data from the drift chambers are mainly represented and processed through the following classes:

- **`TArtDCHit`:** This class object typically represents the hit information of a single anode wire in the drift chamber [5, 8]. It may contain data members such as:
  - Unique identifier of the anode wire (Wire ID)
  - Layer number (Layer ID)
  - Raw TDC value, corresponding to drift time
  - Calibrated drift time
  - Calculated drift distance
  - Possibly ADC values (if the anode wire also measures charge signals, useful for dE/dx information or improving position resolution)
- **`TArtDCTrack`:** This class object represents the track of a charged particle reconstructed from one or more drift chambers [5, 8]. It may contain data members such as:
  - Coordinates of the track's spatial points
  - Position (X, Y) and angle (AngleX, AngleY) of the track in a specific reference plane
  - Quality parameters of the track fit (e.g., $\chi^2$/ndf)
  - List of indices or pointers to the `TArtDCHit` objects constituting this track
  - Reconstructed particle momentum or magnetic rigidity (Bρ) calculated via other means

Users typically obtain the `TClonesArray` containers of these objects from `TArtStoreManager`, e.g., containers named "SAMURAIBDCTrack" or "SAMURAIFDCTrack" may store the reconstructed tracks from BDC or FDC.

#### 5.3 PDC Data Calibration (`TArtCalibDC` or Similar)

The raw data from the drift chambers (mainly TDC values) must be carefully calibrated before they can be used for precise track reconstruction. The calibration process usually includes the following key steps, with parameters typically loaded from XML files [14]:

- **Conversion from Drift Time to Drift Distance (t-d Relationship):** This is the core of the drift chamber calibration. The precise relationship between the measured drift time and the shortest distance between the particle's track and the anode wire (drift distance) needs to be determined for each drift cell (or each type of drift cell). This t-d relationship is usually nonlinear and depends on factors like the type of gas, pressure, temperature, and electric field strength in the drift chamber. It is typically determined through dedicated calibration experiments (e.g., using cosmic rays or specific beam tests with known tracks, or through "self-calibration" methods) and combined with complex fitting procedures [14]. The calibration results (e.g., parameters of the t-d function) are stored for use in subsequent analyses.
- **Determination of Time Zero ($t_0$):** Each TDC channel requires an accurate time zero, corresponding to the TDC reading when the particle passes exactly at the anode wire (drift time is zero). The uncertainty in $t_0$ directly affects the accuracy of drift distance calculations.
- **Signal Amplitude Processing (ADC):** If the drift chamber also records the amplitude of the anode wire signals (ADC values), this information can be used to distinguish events with different ionization capabilities, or to assist in improving position resolution through charge sharing, and even for particle identification (dE/dx). ADC data also require calibration.
- **Geometric Calibration (Alignment):** Precisely knowing the position of each anode wire in space and the relative positions and orientations of the various drift chamber modules (the so-called "intrinsic alignment" and "external alignment") is crucial for track reconstruction. These geometric parameters are usually determined through precise measurements (e.g., optical measurements) and beam test data, and are input as parameters to the analysis software [14].
- **Parameter Files:** All these calibration constants, t-d relationship parameters, geometric parameters, etc., are provided to the calibration and reconstruction modules through ANAROOT's parameter management system (usually XML files, loaded by `TArtSAMURAIParameters` or its subclasses).

#### 5.4 PDC Track Reconstruction and Momentum Analysis

After the calibration of the drift chamber data, track reconstruction and momentum analysis can be performed.

- **Track Finding Algorithm (Track Finding):**
  The track finding process identifies and combines the hit points belonging to the same particle track from the numerous `TArtDCHit` records. For drift chambers with multiple layers of anode wires oriented in different directions, this is a complex combinatorial problem. One approach is that for n hit wires, there are two possible particle passage paths for each wire (left-right ambiguity), leading to $2^n$ combinations of hit positions. Each combination can be fitted with a linear or more complex function, and the one with the best fit quality is accepted as the candidate track [14]. Other more sophisticated algorithms, such as road finding, Hough transform, or stepwise track building methods (like the initial stage of Kalman filtering), may also be used.
- **Track Fitting (Track Fitting):**
  Once candidate tracks are found (i.e., a set of hit points belonging to the same track), fitting algorithms are used to precisely determine the parameters of the track, such as its position and direction in a reference plane. Simple fits can use linear or parabolic models (especially in weak or no magnetic field regions). In strong magnetic fields, the curvature of the particle track needs to be considered, and spiral or more complex numerical integration models may be used. Kalman filtering is a powerful and widely used track fitting technique that iteratively updates track parameters and naturally handles multiple scattering effects [15]. The fitted track parameters, such as position, angle, curvature, and $\chi^2$ value of the fit, are stored in the `TArtDCTrack` object.

  To improve resolution, residual corrections are often performed. Residuals, the differences between the measured hit positions and the predicted positions on the reconstructed track, are analyzed to further correct t-d relationships or local alignment parameters, optimizing track reconstruction accuracy [14].
- **Momentum Reconstruction Using SAMURAI Magnetic Field:**
  The SAMURAI superconducting magnet provides a bending power of up to 7 Tm [12, 13]. Charged particles are deflected by the Lorentz force in the magnetic field, with the radius of deflection proportional to the particle's momentum and inversely proportional to the charge and magnetic field strength. By precisely measuring the curvature of the particle in the magnet (or before and after the magnet), its magnetic rigidity Bρ can be determined. For particles with known charge Z, their momentum p can be calculated using the formula $p = Z \cdot e \cdot B\rho$ (where e is the elementary charge) [14].

  A method called Multi-Dimensional Fit (MDF) is used for fragment tracking in SAMURAI, fitting the known magnetic rigidity (Bρ) and flight length ($l_f$) as functions of the position and angle measured by the drift chambers. The coefficients of these fitting functions (usually polynomial combinations) are trained using a large number of GEANT4 simulated events. In real data analysis, the measured drift chamber data are substituted into these fitting functions to obtain Bρ and $l_f$ for the event [14]. This method relies on accurate GEANT4 simulations, including precise descriptions of the magnetic field map, detector geometry, and material interactions. Any discrepancies between the simulation and the actual setup may introduce systematic errors, making the validation and adjustment of simulation parameters (e.g., magnetic field strength factors) crucial for ensuring momentum reconstruction accuracy.

#### 5.5 Example: PDC Data Analysis Script/Macro

Here is a conceptual skeleton of an ANAROOT analysis macro (C++ ROOT macro) to demonstrate the processing of SAMURAI PDC data. The actual code needs to be adjusted according to the specific ANAROOT version and experimental setup.

```cpp
// MyPDCAnalysis.C
void MyPDCAnalysis(const char* ridfFile = "run0001.ridf", const char* outRootFile = "pdc_hists.root") {
    // 1. ANAROOT environment initialization (usually done in rootlogon.C or setup.sh)
    // gSystem->Load("libanacore.so"); // etc. ANAROOT core libraries
    // gSystem->Load("libanasamurai.so"); // etc. SAMURAI related libraries

    // 2. Create parameter manager and load parameter files
    TArtSAMURAIParameters *samuraiPara = TArtSAMURAIParameters::Instance();
    samuraiPara->LoadParameter("db/SAMURAIBDC.xml"); // BDC parameters
    samuraiPara->LoadParameter("db/SAMURAIFDC.xml"); // FDC parameters
    //... other necessary parameter files

    // 3. Create and configure EventStore
    TArtEventStore *estore = new TArtEventStore();
    estore->Open(ridfFile);

    // 4. Create calibration/reconstruction objects (usually done in AnaLoop's Construct)
    // For example: TArtCalibBDC *calibBDC = new TArtCalibBDC();
    // TArtCalibFDC *calibFDC = new TArtCalibFDC();
    // TArtRecoDCTrack *recoTrack = new TArtRecoDCTrack(); // assuming such a track reconstruction class exists

    // 5. Pre-allocate histograms
    TFile *outFile = new TFile(outRootFile, "RECREATE");
    TH1F *h_fdc_x = new TH1F("h_fdc_x", "FDC Track X Position; X (mm); Counts", 200, -1000, 1000);
    TH1F *h_fdc_p = new TH1F("h_fdc_p", "FDC Track Momentum; p (MeV/c); Counts", 200, 0, 3000);
    //... more histograms

    // 6. Event loop
    TArtStoreManager *sman = TArtStoreManager::Instance();
    while (estore->GetNextEvent()) {
        // Clear data from the previous event (usually handled within Calib/Reco objects)
        // calibBDC->ClearData(); calibFDC->ClearData(); recoTrack->ClearData();

        // Perform calibration and reconstruction (usually handled within Calib/Reco objects, which get raw data from estore)
        // calibBDC->ReconstructData();
        // calibFDC->ReconstructData();
        // recoTrack->ReconstructData(); // depends on calibrated DCHit

        // 7. Retrieve reconstructed data containers from StoreManager
        TClonesArray *fdcTracks = (TClonesArray*)sman->FindDataContainer("SAMURAIFDCTrack"); // assuming the reconstructed track container is named this

        if (fdcTracks) {
            int nTracks = fdcTracks->GetEntriesFast();
            for (int i = 0; i < nTracks; ++i) {
                TArtDCTrack *track = (TArtDCTrack*)fdcTracks->At(i);
                if (track) {
                    // Access track parameters and fill histograms
                    h_fdc_x->Fill(track->GetPositionX()); // assuming there is a GetPositionX() method
                    // h_fdc_p->Fill(track->GetMomentum()); // assuming there is a GetMomentum() method
                    //... access data using actual TArtDCTrack class methods
                }
            }
        }
        estore->ClearData(); // Clear raw data cache in TArtEventStore
    }

    // 8. Save histograms and close file
    outFile->Write();
    outFile->Close();

    delete estore;
    // delete calibBDC; delete calibFDC; delete recoTrack; // if created here
    delete outFile;

    std::cout << "Analysis finished. Output saved to " << outRootFile << std::endl;
}
```

**Note:** The above code is a highly simplified example framework. Actual ANAROOT analyses typically use derived classes of `TArtAnaLoop` to organize analysis logic, with object creation and configuration in the `Construct()` method, event processing in the `Calculate()` method, and cleanup in the `Destruct()` method. The exact names of data containers (`"SAMURAIFDCTrack"`) and methods of `TArtDCTrack` (`GetPositionX`, `GetMomentum`) need to be referenced from the actual implementation in the specific ANAROOT version and SAMURAI analysis modules.

- **Table 3: SAMURAI PDC (Drift Chamber) Data Parameter Examples (in ANAROOT)**

| Parameter Name in Class - Example | Class e.g., TArtDCHit, TArtDCTrack | Description | Unit | Snippet Ref. |
| :-------------------------------- | :---------------------------------- | :-------------------------------------------------- | :------------- | :------------------------------- |
| `GetTDC()`                       | `TArtDCHit`                        | Raw TDC value, related to drift time               | channels       | [5, 8] (inferred)               |
| `GetDriftLength()`              | `TArtDCHit`                        | Drift distance calculated from t-d relationship    | mm             | [5, 8] (inferred)[14]           |
| `GetWireID()`                   | `TArtDCHit`                        | Unique identifier for the hit anode wire           | N/A            | (ANAROOT common structure)      |
| `GetLayer()`                    | `TArtDCHit`                        | Layer number of the anode wire                     | N/A            | (ANAROOT common structure)      |
| `GetPositionX()`, `GetPositionY()` | `TArtDCTrack`                     | X, Y coordinates of the reconstructed track         | mm             | [5, 8] (inferred)[14]           |
| `GetAngleX()`, `GetAngleY()`    | `TArtDCTrack`                     | Direction angles of the reconstructed track         | mrad or rad    | [5, 8] (inferred)[14]           |
| `GetMomentum()`                 | `TArtDCTrack` (or related recon class) | Reconstructed particle momentum                      | MeV/c or GeV/c | [14, 12, 13] (physical target)  |
| `GetBrho()`                     | `TArtDCTrack` (or related recon class) | Reconstructed particle magnetic rigidity            | Tm              | [14] (physical target)          |
| `GetChi2()`                     | `TArtDCTrack`                     | Chi-squared value of the track fit                 | N/A            | (standard track parameter)      |

This table aims to help users understand the key physical information or intermediate quantities that can be obtained from ANAROOT data containers when analyzing SAMURAI drift chamber data, and guide them on how to access these quantities in their analysis code. The actual available method and variable names should be referenced from the class documentation of the corresponding ANAROOT version.

### 6. Using ANAROOT to Analyze NEBULA Detector Data

NEBULA (Neutron Detection System for Breakup of Unstable Nuclei with Large Acceptance) is an important subsystem in the SAMURAI experiment for neutron detection. This section will introduce how to use ANAROOT to analyze data from the NEBULA detectors.

#### 6.1 Introduction to NEBULA Detectors

[14, 16, 17] The NEBULA detector array consists of multiple layers of plastic scintillator bars, with photomultiplier tubes (PMTs) read out at both ends of each scintillator bar [17]. When fast neutrons interact with the plastic scintillator, they primarily transfer part of their energy to protons through elastic scattering. These recoil protons produce scintillation light in the scintillator, which is collected by the PMTs and converted into electrical signals [18]. NEBULA is designed to detect one or more neutrons emitted from nuclear reactions and can measure their time and energy deposition information, allowing for the reconstruction of the neutrons' energy and momentum [17]. NEBULA-Plus is an upgraded version of NEBULA, which increases detection efficiency, especially for events with multiple neutrons, by adding extra detector walls [17].

#### 6.2 Characteristics of NEBULA Data and Their Representation in ANAROOT

In ANAROOT, the data from the NEBULA plastic scintillators are mainly represented by the `TArtNEBULAPla` class [5, 8]. A `TArtNEBULAPla` object typically corresponds to a single hit event in one of the plastic scintillator bars of the NEBULA array. It may contain data members such as:

- ID of the detector unit (bar) (Bar ID)
- Raw TDC values from both ends PMTs (TDC_L, TDC_R)
- Raw ADC or QDC values from both ends PMTs (ADC_L, ADC_R or QDC_L, QDC_R), reflecting energy deposition
- Calibrated time information (e.g., hit times Time_L, Time_R, or mean time Time_Mean)
- Calibrated energy deposition information (e.g., Q_L, Q_R, or geometric mean Q_Mean)
- Calculated hit position (Position)
- Calculated time of flight (TOF)
- Pulse shape discrimination (PSD) parameters (if supported and calculated)

If the NEBULA experimental configuration also includes high-purity germanium detectors (HPGe) for coincident gamma-ray detection, the `TArtNEBULAHPC` class may also be used [5, 8]. This guide will mainly focus on neutron analysis based on `TArtNEBULAPla`. Users obtain the `TClonesArray` data container named "NEBULAPla" (or similar) through `TArtStoreManager`.

#### 6.3 NEBULA Data Calibration (`TArtCalibNEBULA` or Similar) [14]

Accurate calibration of NEBULA data is crucial for subsequent neutron identification and physical analysis.

- **Timing Calibration:**
  - **TDC Conversion:** Converts the raw TDC counts of each PMT to time in nanoseconds (ns). This is usually done through linear calibration using pulse signals with known time intervals (e.g., electronic test pulses or cosmic ray events) [14].
  - **Walk Correction:** The leading edge timing of PMT signals may vary with signal amplitude (the "Walk effect"), causing larger signals to appear earlier. Corrections are needed for the time based on signal amplitude (ADC/QDC values). Common correction function forms are like $t_{corr} = t_{raw} - (a/\sqrt{Q} + b)$ or similar, where Q is the charge value, and a and b are fitting parameters [14].
  - **Intra-bar Time Synchronization and Absolute Time Zero Point:** Synchronizes the time response of the two PMTs at each end of the bar and determines the absolute time zero point of the entire detector relative to the experimental trigger or beam signal. This is usually done using prompt $\gamma$-ray events from the target as a reference, adjusting the time offsets of each PMT based on the known speed of light [14].
  - **In-run Time Drift Correction:** The time response of the detector and electronics may drift slowly during the experiment, requiring monitoring and correction, for example, using the average time of cosmic rays or $\gamma$-flash as a reference [14].

- **Position Calibration:**
  The interaction position of neutrons in the scintillator bars can be determined by measuring the time difference $\Delta t = t_L - t_R$ between the signals arriving at the two PMTs. The position $x$ is approximately linearly related to $\Delta t$: $x \approx v_{eff} \cdot \Delta t / 2 + x_0$, where $v_{eff}$ is the effective speed of light in the scintillator, and $x_0$ is the position of the bar's center or one end. The values of $v_{eff}$ and $x_0$ need to be determined through calibration, for example, using $\gamma$ sources with known positions irradiating different positions of the scintillator bar, or cosmic ray tracks passing through the entire bar and producing signals at both ends [14].

- **Energy Calibration (Light Output):**
  The charge measured by the PMTs (ADC/QDC values) needs to be converted to the energy deposited by the particles in the scintillator, usually in units of MeVee (MeV electron equivalent). For neutron detection, the energy of interest is that deposited by the recoil protons. The light output of plastic scintillators varies for different types of incident particles, and the relationship between the light output for protons and their energy is typically nonlinear, which can be described by models like Birks' law [14]. Energy calibration is usually performed using $\gamma$ sources with known energies (e.g., $^{60}Co$, $^{137}Cs$, using their Compton edge) or the energy loss of cosmic $\mu$-mesons.

  All these calibration parameters (TDC conversion factors, Walk correction parameters, time offsets, position calibration coefficients, energy calibration function parameters, etc.) are provided to the calibration and reconstruction modules through ANAROOT's parameter management system (usually XML files, loaded by `TArtSAMURAIParameters` or its subclasses).

#### 6.4 NEBULA Neutron Identification and Analysis Techniques

- **Time-of-Flight (TOF) Calculation of Neutron Energy/Momentum:**
  Neutrons are electrically neutral and cannot be directly measured for momentum. Their kinetic energy is primarily determined by measuring the time-of-flight (TOF) [14]. TOF is the time taken by the neutron to travel from the point of production in the target to the point of first interaction in NEBULA. The flight path length $L$ is the straight-line distance from the reaction target to the neutron interaction point in NEBULA. Once TOF and $L$ are known, the neutron's speed $v = L/TOF$ can be calculated.

  For non-relativistic neutrons, the kinetic energy $KE = \frac{1}{2} m_n v^2$, where $m_n$ is the neutron mass. For high-energy neutrons produced in RIBF experiments, relativistic formulas are used: $KE = (\gamma - 1)m_n c^2$, where the Lorentz factor $\gamma = 1/\sqrt{1 - (v/c)^2}$. The neutron momentum $p = \gamma m_n v$.

  Accurate TOF measurement requires a precise "start" time signal (usually from beam or target prompt signals) and a precise "stop" time signal (from NEBULA PMT). The calculation of the flight path $L$ relies on the precise reconstruction of the reaction vertex and the neutron interaction point in NEBULA.
- **Pulse Shape Discrimination (PSD):**
  Plastic scintillators (especially certain types or specially treated ones) produce scintillation light with subtle differences in pulse shape for different types of incident particles (e.g., $\gamma$-rays and neutrons). Neutrons primarily produce light through recoil protons, while $\gamma$-rays primarily produce light through Compton scattering electrons. Recoil protons usually produce more slow-decaying light signal components. This characteristic can be used to distinguish neutron events from $\gamma$ background events by analyzing the shape of the PMT output pulses (e.g., comparing the charge integration ratios in different time windows, the so-called "long-short gate" method or "tail-to-total" method) [14, 18]. PSD is a key technique for pure neutron measurements, especially in experimental environments with high $\gamma$ backgrounds. In ANAROOT, PSD parameters calculation and cut settings may be performed by `TArtCalibNEBULA` or user-implemented algorithms in `AnaLoop`.
- **Cross-talk Correction:** [14]
  An incident neutron may scatter multiple times in the NEBULA detector array, with each scatter potentially producing signals in one or more scintillator bars, leading to "scatter cross-talk". Additionally, secondary particles (like another neutron or $\gamma$-ray) produced from a primary neutron interaction may hit other bars, causing "secondary particle cross-talk". These cross-talk events complicate the determination of the number and energy of incident neutrons.

  ANAROOT (or user analysis code) needs to employ algorithms to identify and exclude these cross-talk signals to correctly reconstruct the true neutron hit information. The cross-talk exclusion steps mentioned in [14] include:
  1.  **TOF Cut:** Exclude events with TOF too small or too large, typically corresponding to random coincidences or accelerator-related backgrounds.
  2.  **Clustering:** Combine temporally and spatially adjacent hits into "clusters". This helps to exclude most cross-talk caused by secondary charged particles.
  3.  **Energy Threshold Cut (Q-cut):** Clusters with total energy deposition below a certain threshold (e.g., 5 MeVee) are considered cross-talk. The first hit of the cluster should also have sufficient energy deposition to ensure good TOF resolution. This helps to exclude low-energy $\gamma$-rays and scattered neutron-induced cross-talk.
  4.  **$\gamma$ Cross-talk Exclusion:** Identify high-energy $\gamma$-ray induced cross-talk by comparing the characteristics of the cluster pairs (e.g., relative speed close to the speed of light and low energy).
  5.  **Causality Cut:** Utilize the characteristic of scattered neutrons slowing down after energy loss. If a cluster can be explained as being produced by a neutron scattered from a previous cluster, the latter is considered cross-talk.
  6.  **Nearby Cross-talk:** Especially for NeuLAND, apply additional spatial distance cuts for potential cross-talks that might survive due to insufficient resolution between small-distance clusters.
  7.  **Veto Condition:** Use the signals from the charged particle vetoes in front of the NEBULA wall to exclude false neutron signals caused by charged particles in the detector wall behind.

- **Efficiency and Acceptance Correction:**
  The detection efficiency of the NEBULA detector for neutrons is not 100% and depends on the energy of the neutrons. Also, due to geometric limitations, the detector can only cover a part of the solid angle (i.e., acceptance). To obtain the true physical yield, the measured neutron counts need to be corrected for detection efficiency and acceptance. These correction factors are usually obtained through detailed Monte Carlo simulations (e.g., using the GEANT4 software package) [14]. The simulations need to accurately describe the geometry of the detector, the materials used, and the physical processes of neutron interactions with matter. The simulation results often need to be validated and adjusted with experimental data, for example, using neutron sources with known yields and angular distributions (e.g., $^{252}$Cf spontaneous fission source) or specific nuclear reactions (e.g., $^7\text{Li}(p,n)^7\text{Be}$ reaction [17]) for calibration and efficiency determination. In [14], it is mentioned that the single neutron detection efficiency from simulations is scaled by a global factor based on dedicated experimental results.

#### 6.5 Example: NEBULA Data Analysis Script/Macro

Here is a conceptual skeleton of an ANAROOT analysis macro (C++ ROOT macro) to demonstrate the processing of NEBULA data.

```cpp
// MyNEBULAAnalysis.C
void MyNEBULAAnalysis(const char* ridfFile = "run0001.ridf", const char* outRootFile = "nebula_hists.root") {
    // 1. ANAROOT environment initialization (usually done in rootlogon.C or setup.sh)
    // gSystem->Load("libanacore.so");
    // gSystem->Load("libanasamurai.so"); // Includes NEBULA related classes

    // 2. Create parameter manager and load parameter files
    TArtSAMURAIParameters *samuraiPara = TArtSAMURAIParameters::Instance(); // Or TArtNEBULAParameters if exists
    samuraiPara->LoadParameter("db/NEBULA.xml"); // NEBULA parameters file
    //... other necessary parameter files

    // 3. Create and configure EventStore
    TArtEventStore *estore = new TArtEventStore();
    estore->Open(ridfFile);

    // 4. Create calibration objects (usually done in AnaLoop's Construct)
    TArtCalibNEBULA *calibNEBULA = new TArtCalibNEBULA(); // Hypothetical NEBULA calibration class

    // 5. Pre-allocate histograms
    TFile *outFile = new TFile(outRootFile, "RECREATE");
    TH1F *h_nebula_tof = new TH1F("h_nebula_tof", "NEBULA TOF; TOF (ns); Counts", 500, 0, 500);
    TH1F *h_nebula_q = new TH1F("h_nebula_q", "NEBULA QDC (Mean); Q (MeVee); Counts", 200, 0, 100);
    TH2F *h_psd_q = new TH2F("h_psd_q", "NEBULA PSD vs Q; Q (MeVee); PSD parameter", 200, 0, 100, 200, 0, 2);
    //... more histograms

    // 6. Event loop
    TArtStoreManager *sman = TArtStoreManager::Instance();
    while (estore->GetNextEvent()) {
        calibNEBULA->ClearData();
        calibNEBULA->ReconstructData(); // Perform calibration and initial processing of NEBULA data

        // 7. Retrieve NEBULA data containers from StoreManager
        TClonesArray *nebulaPlaArray = (TClonesArray*)sman->FindDataContainer("NEBULAPla"); // Assuming container name is NEBULAPla

        if (nebulaPlaArray) {
            int nHits = nebulaPlaArray->GetEntriesFast();
            for (int i = 0; i < nHits; ++i) {
                TArtNEBULAPla *pla = (TArtNEBULAPla*)nebulaPlaArray->At(i);
                if (pla) {
                    // Access NEBULA plastic bar data and fill histograms
                    // double tof = pla->GetTOF(); // Assuming there is a GetTOF() method, may need to calculate with target time
                    // double q_mean = pla->GetQ();   // Assuming there is a GetQ() method to get calibrated energy deposition
                    // double psd_param = pla->GetPSD(); // Assuming there is a GetPSD() method to get PSD parameter

                    // h_nebula_tof->Fill(tof);
                    // h_nebula_q->Fill(q_mean);
                    // h_psd_q->Fill(q_mean, psd_param);
                    //... access data using actual TArtNEBULAPla class methods
                }
            }
        }
        estore->ClearData();
    }

    // 8. Save histograms and close file
    outFile->Write();
    outFile->Close();

    delete estore;
    delete calibNEBULA;
    delete outFile;

    std::cout << "NEBULA analysis finished. Output saved to " << outRootFile << std::endl;
}
```

**Note:** Similar to the PDC example, this is a conceptual framework. Actual usage should derive from `TArtAnaLoop`. The methods of `TArtCalibNEBULA` and `TArtNEBULAPla` (e.g., `GetTOF()`, `GetQ()`, `GetPSD()`) need to be based on the actual definitions in ANAROOT. TOF calculation usually requires a start time reference (e.g., target signal or beam plastic scintillator signal), which may need to be handled additionally in `AnaLoop`.

- **Table 4: NEBULA Data Parameter Examples (in ANAROOT)**

| Parameter Name in Class - Example | Class e.g., TArtNEBULAPla | Description | Unit | Snippet Ref. |
| :-------------------------------- | :------------------------- | :------------------------------------------------------ | :---------- | :--------------------------- |
| `GetID()`                        | `TArtNEBULAPla`           | ID of the scintillator bar                              | N/A         | [5, 8] (inferred)           |
| `GetTDC(pmt_id)`                | `TArtNEBULAPla`           | Raw TDC value of PMT (0 or 1)                          | channels    | [5, 8] (inferred)           |
| `GetQDC(pmt_id)` or `GetADC(pmt_id)` | `TArtNEBULAPla`           | Raw ADC/QDC value of PMT (0 or 1)                      | channels    | [5, 8] (inferred)           |
| `GetTime()`                     | `TArtNEBULAPla`           | Calibrated average hit time                             | ns          | [14] (physical target)      |
| `GetPos()`                      | `TArtNEBULAPla`           | Calculated hit position along the bar                  | mm          | [14] (physical target)      |
| `GetQ()`                        | `TArtNEBULAPla`           | Calibrated total energy deposition                      | MeVee       | [14] (physical target)      |
| `GetTOF()`                      | `TArtNEBULAPla` (or user calc) | Time of flight (usually needs start signal reference)  | ns          | (core physical quantity)    |
| `GetPSDValue()`                 | `TArtNEBULAPla` (or user calc) | Pulse shape discrimination parameter                    | (arbitrary unit) | [14] (technical requirement) |

This table provides users with key information that can be accessed in `TArtNEBULAPla` objects for neutron data analysis, guiding them in accessing these quantities in their analysis code. The actual available method and variable names should be referenced from the class documentation of the corresponding ANAROOT version.

---

## Part III: Advanced Usage of ANAROOT

### 7. ANAROOT Analysis Workflow Control and Script Writing

#### 7.1 Detailed Explanation of `AnaLoop`

`AnaLoop` (with the exact base class name `TArtAnaLoop`) is the core abstract class in ANAROOT for controlling user-defined analysis workflows [10]. Users build their analysis modules by inheriting `TArtAnaLoop` and overriding its specific virtual functions. The main functions that need to be implemented include:

- **`Construct()`**: Called once at the beginning of the analysis (after the `start()` command) [20]. Its main purpose is to perform initialization tasks before the analysis, such as creating and configuring instances of calibrator (`TArtCalibXXX`) and reconstructor (`TArtRecoXXX`) objects (e.g., `new TArtCalibNEBULA()`), and pre-allocating (booking) the histograms (`TH1`, `TH2`) and N-tuples (`TNtuple` or `TTree`) needed by the user [10].
- **`Calculate()`**: Called once for each event in the event loop [10]. This is where the main analysis logic is executed, including:
  - Retrieving the various data containers (e.g., `TArtDCHit`, `TArtNEBULAPla`, etc.) for the current event from `TArtStoreManager`.
  - Applying selection criteria (cuts) based on the retrieved data, calculating derived physical quantities, and filling the histograms and N-tuples booked in `Construct()`.
- **`Destruct()`**: Called once at the end of the analysis (when the `end()` command is issued or the analysis workflow is terminated normally) [20]. Its main purpose is to release the objects created in `Construct()` and perform necessary cleanup to prevent memory leaks [10].
- **`ClassName()`**: A simple helper function that returns the name of the current `AnaLoop` derived class, mainly for display in the output of the `status()` command [10].

Users can use their custom `AnaLoop` in two main ways:
1.  **Built-in to library:** Place the derived class source files (`.hh` and `.cc`) in specific directories of the ANAROOT source (e.g., `$TARTSYS/source/AnaLoop/include` and `$TARTSYS/source/AnaLoop/src`), and recompile the entire ANAROOT library. This is suitable for providing analysis modules to users who do not wish to delve into code details, forming a "black box" analysis module [10].
2.  **Load dynamically as a macro:** Create the source file of the derived class in the user’s working directory (e.g., `MyAnaLoop.C`), and compile and load it in the ROOT/ANAROOT interactive session using the `.L MyAnaLoop.C+` command (note the `+` at the end indicates compilation) [10, 4]. This is very convenient for users who need to frequently modify and test analysis logic, as it avoids the time-consuming process of recompiling the entire ANAROOT library.

`TArtAnaLoop` is central to implementing customized analyses in ANAROOT. It provides a clear structure for managing the lifecycle of analysis objects and processing the event data flow. The ability to dynamically load `AnaLoop` macros offers great convenience for rapid development and debugging of analysis codes.

A special `AnaLoop` derived class is `TAlEncExample`. This class is typically used when users want to combine analysis with `Anafile` (see section 7.2). `TAlEncExample` internally registers a series of sub-analysis modules inheriting from `TAlEncSub` (like `TAlEncSAMURAIExample`, `TAlEncDALIExample`, `TAlEncNEBULAExample`), and calls these sub-modules in the order specified by the `<analys>` tag in the `Anafile` for analysis [10].

#### 7.2 Using `Anafile`: Defining Histograms, Cut Conditions, and Ntuple

`Anafile` is a text-based configuration file format used to define histograms, set data selection conditions (cuts), and define the structure of N-tuples in a non-programming way for online or quick offline analysis [1, 4]. When using an `AnaLoop` like `TAlEncExample`, an `Anafile` can be associated with the analysis workflow using the `book(new TAlEncExample, "myconfig.ana")` command [4].

The syntax of `Anafile` includes a series of specific tags and parameters [1]:
- **`<analys> id1,id2,...</analys>`**: Specifies the execution order of the analysis modules. The IDs here correspond to the enum values of the registered `TAlEncSub` modules in `TAlEncExample`.
- **`<include> "path/to/another.ana"</include>`**: Includes another `Anafile`, facilitating modular management of configurations.
- **`<gate> gate_id, {analyser_id,start_id,end_id,wnum}, low_val, high_val, "title"</gate>`**: Defines a one-dimensional gate (cut condition).
  - `gate_id`: Unique identifier for the gate.
  - `{analyser_id,start_id,end_id,wnum}`: Specifies the physical quantity for the gate. `analyser_id` is the `EAnalyser` value, `start_id` and `end_id` define the range of detectors or channels, `wnum` is the `EWNum` value representing the specific physical quantity (like TOF, energy deposition, etc.) [10].
  - `low_val`, `high_val`: Lower and upper limits of the gate.
  - `"title"`: Descriptive title for the gate.
- **`<and> new_gate_id, gate_id1, gate_id2,..., "title"</and>`**: Combines multiple defined gates into a new gate using a logical "AND" operation.
- **`<or> new_gate_id, gate_id1, gate_id2,..., "title"</or>`**: Combines multiple defined gates into a new gate using a logical "OR" operation.
- **1D Histogram Definition:** `gate_id, analyser_id,start_id,end_id,wnum, nbins, xlow, xhigh, "
title"`
  - `gate_id`: The gate ID applied to this histogram (0 for no gate).
  - `analyser_id,start_id,end_id,wnum`: Similar to gate definition, defines the physical quantity and range for the histogram.
  - `nbins`, `xlow`, `xhigh`: Define the X-axis of the histogram.
- **2D Histogram Definition:** `gate_id, analyser_id_X,start_id_X,end_id_X,wnum_X, nbinsX, xlow, xhigh, analyser_id_Y,start_id_Y,end_id_Y,wnum_Y, nbinsY, ylow, yhigh, "title"`
  - Defines the physical quantities and ranges for the X and Y axes, respectively.

`EAnalyser` and `EWNum` are enumeration types defined internally in ANAROOT (usually in files like `EAnalyser.hh` and `EWNum.hh`), used to uniquely identify different analysis modules (detector systems) and the physical quantities they produce [10]. Users can view the list of these enumerations in the ANAROOT CUI using the `lv()` command.

`Anafile` provides a relatively simple, text-based configuration method, especially suitable for online monitoring and quick exploratory data analysis, lowering the threshold for users unfamiliar with C++ programming to perform basic analysis setup.

#### 7.3 Command-Line Interface (CUI) and Common Commands

ANAROOT provides a command-line based User Interface (CUI), styled after the earlier ANAPAW analysis software, and implemented using the Nadeko library [1]. This CUI allows users to interactively control the analysis flow, manage histograms, and more. Here are some common CUI commands and their functions [20]:

**Analysis Management Commands:**
- `book(TArtAnaLoop* analoop, const char* anafilename = 0)`: Register an `AnaLoop` object, optionally associating an `Anafile`. This is a mandatory step before starting the analysis. Example: `book(new TAlRawDataExample, "rawdata.ana")` [20, 4].
- `push(const char* filename, int eventnumber = -1)`: Push a RIDF data file onto the file stack to be processed. The `eventnumber` parameter can limit the number of events to be processed from that file (-1 means all events). Example: `push("run0007.ridf")` [20, 4].
- `push(int sid = 0, int eventnumber = -1)`: Connect to an online shared memory data source. `sid` is the shared memory ID. Example: `push(0)` connects to shared memory with ID 0 [20, 4].
- `spush(const char* filename_start, const char* filename_end, int start_run, int end_run, int width = 4, char fill = '0')`: Push multiple RIDF files with similar naming patterns at once. For example, `spush("ridf/run", ".ridf", 1, 11)` pushes files from `ridf/run0001.ridf` to `ridf/run0011.ridf` [20].
- `pop(int i)`: Pop the file at the specified index from the file stack [20].
- `start()`: Start the event loop and begin data analysis. The `Construct()` method of `AnaLoop` is called the first time `start()` is invoked [20, 4].
- `stop()`: Pause the ongoing analysis. The analysis can be resumed with the `start()` command [20].
- `next()`: Skip the remaining events in the current RIDF file and process the next file in the stack [20].
- `join()`: (Mainly for macros) Wait for the current analysis task to complete. This command ensures that the main thread (like a macro script) does not exit before the analysis is finished, as the analysis might be running in a background thread [20].
- `end()`: Terminate the current analysis. The `Destruct()` method of `AnaLoop` is called [20].
- `clear()`: Clear all booked histograms and destroy the `TArtAnaLoopManager` object, resetting the analysis environment [20].
- `status()`: Print the status information of the current analysis, such as the number of processed events, file stack content, current `AnaLoop` class name, etc. [20].

**Histogram Management Commands:**
- `fetch(char* filename)`: Read all `TH1` objects from the specified ROOT file into the current ROOT directory [20].
- `hstore(char* filename)`: Save all `TH1` objects from the current ROOT directory to the specified ROOT file [20].
- `hdel(int id_start = -1, int id_end = -1)`: Delete histograms in the specified ID range (deletes all if no parameters are specified) [20].
- `erase()`: Reset (clear content but keep definition) all histograms in the current ROOT directory [20].
- `ls()`: List the objects in the current ROOT directory (similar to the shell's ls command) [20].
- `ht(int id, Option_t* option = "")`: Draw the histogram with the specified ID. The `option` parameter can be passed to ROOT's `Draw()` method (like "SAME", "COLZ", etc.) [20, 4].
- `htp()`: Draw the currently active histogram [20].
- `hn()`: Draw the histogram with the next ID [20, 4].
- `hb()`: Draw the histogram with the previous ID [20].
- `lg()`, `ln()`, `lgx()`, `lgy()`, `lgz()`, `lnx()`, `lny()`, `lnz()`: Set or unset the logarithmic scale for the axes on the canvas [20].
- `size(UInt_t ww, UInt_t wh)`: Change the size of the current canvas [20].
- `cd(Int_t subpadnumber = 0)`: Switch the currently active sub-pad on the canvas [20].

A typical interactive analysis session might proceed as follows:
1.  Start ROOT and load ANAROOT library: `root -l`, `gSystem->Load("libXMLParser.so"); gSystem->Load("libanaroot.so");` [4].
2.  Register `AnaLoop` and `Anafile` (if used): `book(new MyPDCNEBULAAnalysis, "pdc_nebula.ana");`
3.  Push data files: `push("data/run0123.ridf"); push("data/run0124.ridf");`
4.  Start analysis: `start();`
5.  View histograms during or after analysis: `ht(101); hn();`
6.  Store results: `hstore("results/my_analysis_hists.root");`
7.  End analysis session: `end();.q`

#### 7.4 Writing and Using ROOT Macros for Analysis

In addition to interactive CUI operations, the analysis workflow in ANAROOT can also be automated and batch-processed by writing ROOT macros (C++ scripts) [21, 22]. Some example macros are provided in the `example/Macros/` directory of ANAROOT, such as `RIDF2Tree.C` (convert RIDF data to TTree), `Online/ShowModule.C` (online display of module count rates), `BigRIPS/RecoPID.C` (BigRIPS particle identification and reconstruction), etc. [4].

In ROOT macros, both ANAROOT CUI commands (executed via `gROOT->ProcessLine(".command")`) and direct calls to ANAROOT C++ classes and methods can be combined.

A typical structure of an analysis macro may include:
1.  Load necessary ANAROOT libraries.
2.  Create and configure parameter manager objects (like `TArtSAMURAIParameters`), and load XML parameter files.
3.  Create `TArtEventStore` object and open data file(s).
4.  Create user-defined `AnaLoop` object (or directly implement event loop and analysis logic in the macro, if the analysis is relatively simple).
5.  If using `AnaLoop`, register it with the `book()` command.
6.  Start the event loop (either by directly calling `estore->GetNextEvent()` in a loop, or by controlling `AnaLoop` execution with `start()` and `join()` commands).
7.  Inside the event loop, get the `TArtStoreManager` instance, and extract the needed raw, calibrated, or reconstructed data containers (like `TArtDCHit`, `TArtDCTrack`, `TArtNEBULAPla`).
8.  Process the data, apply selection criteria, fill histograms and N-tuples.
9.  After analysis is complete, save results to ROOT file or other formats.

For example, the `RecoPID.C` macro demonstrates how to load BigRIPS-related parameters, loop over events, perform PID reconstruction, and output ROOT files containing PID-related histograms and N-tuples [2, 4]. Users can refer to this structure to write dedicated macros for analyzing SAMURAI PDC and NEBULA data.

- **Table 5: Common ANAROOT CUI Commands and Their Usage**

| Command (命令) | Main Function (主要功能) | Example Usage (示例用法) | Relevant Source (相关来源) |
| :------------------------------------- | :----------------------------------------------- | :------------------------------------------------------ | :------------------------------- |
| `book(loop, anafile)` | Register AnaLoop and Anafile | `book(new TAlRawDataExample, "raw.ana")` | [20, 4] |
| `push("filename")` 或 `push(shm_id)` | Add RIDF file or connect shared memory data source | `push("run0123.ridf")`, `push(0)` | [20, 4] |
| `start()` | Start the analysis event loop | `start()` | [20, 4] |
| `stop()` | Pause the current analysis | `stop()` | [20] |
| `join()` | Wait for the analysis to complete | `root .x myMacroWithStartJoin.C` | [20] |
| `end()` | End the current analysis session, call AnaLoop's Destruct | `end()` | [20] |
| `hstore("output.root")` | Save all histograms in the current memory to the specified ROOT file | `hstore("myhists.root")` | [20] |
| `ht(histogram_id)` | Draw the histogram with the specified ID | `ht(101)` | [20, 4] |
| `hn()` | Draw the histogram with the next ID | `hn()` | [20, 4] |
| `status()` | Display the status information of the current analysis | `status()` | [20] |
| `clear()` | Clear all histograms and destroy AnaLoopManager | `clear()` | [20] |
| `gSystem->Load("libname.so")` | (ROOT command) Load shared library | `gSystem->Load("libanaroot.so")` | [4] |
| `.L YourAnaLoop.C+` | (ROOT command) Compile and load user-defined AnaLoop macro | `.L MyPDCAna.C+` | [10, 4] |

This table provides users with a quick reference to common CUI commands, helping them quickly get started with the interactive analysis environment of ANAROOT, and effectively control the analysis workflow and manage histograms.

### 8. Data Visualization and Result Output

Data visualization is a key aspect of physical analysis for understanding data features, checking calibration quality, and presenting physical results. ANAROOT, relying on the ROOT framework, provides powerful visualization capabilities. Also, properly saving the analysis results in appropriate formats is crucial for further processing and publication of results.

#### 8.1 Visualization of Histograms and Ntuple with ROOT

[1, 23, 24, 19] The histograms created in ANAROOT are essentially ROOT's `TH1` (one-dimensional), `TH2` (two-dimensional), or `TH3` (three-dimensional) series objects [23, 24]. Therefore, all the rich histogram plotting and manipulation features provided by ROOT can be directly applied to the analysis results of ANAROOT.

- **Histogram Drawing:** In the CUI of ANAROOT, commands like `ht(id)`, `hn()`, `hb()`, `htp()` can be used to quickly draw the filled histograms [20]. In ROOT macros or compiled code, the `TH1::Draw()` method can be called directly, along with various drawing options (like "COLZ" for color-filled 2D plots, "SAME" to overlay multiple histograms, "E" for error bars, etc.).
- **Histogram Operations:** ROOT allows various operations on histograms, such as rebinning (Rebin), normalization (Normalize), arithmetic operations, projections (ProjectionX, ProjectionY), fitting (Fit), etc. These features are very useful for data analysis and result extraction. For example, one can project the PSD parameter vs energy deposition 2D plot from NEBULA to obtain the PSD distribution for a specific energy region, and then fit it to distinguish between neutron and $\gamma$-ray signals.
- **Ntuple/TTree Visualization:** The Ntuple or TTree produced in ANAROOT analyses (e.g., the raw data Ntuple created by `TAlRawDataExample` [4], or user-created TTrees containing reconstructed physical quantities) can be visualized using the powerful `TTree::Draw()` method. This method allows users to plot one-dimensional, two-dimensional, or three-dimensional relationship graphs between arbitrary variables with flexible expressions, and apply complex cutting conditions. For example, `ntp->Draw("NEBULAPla.fTOF:NEBULAPla.fQ", "NEBULAPla.fPSD > 0.5 && SAMURAIDCTrack.fMomentum > 1000")` can draw a 2D scatter plot of TOF vs Q for NEBULA hits that satisfy specific PSD and PDC momentum conditions. The `TTree::Scan()` method can list the entries of the Ntuple that satisfy certain conditions, and `TTree::Print()` can display the structure of the Ntuple.
- **ROOT Graphics Interface:** `TBrowser` is a powerful graphical browser provided by ROOT, through which users can visually browse the contents of ROOT files, view and manipulate histograms, Ntuple, and other objects, and perform interactive fitting, modify drawing attributes, etc.

#### 8.2 Saving Analysis Results (ROOT Files, Text Files, etc.)

The histograms, Ntuple/TTree, and other important result objects generated during the analysis need to be properly saved for later review, further analysis, or publication. 

- **Saving to ROOT Files:**
  - Using the CUI command `hstore("filename.root")` saves all `TH1` objects (including `TH2`, `TH3`) in the current ANAROOT session memory to a new or existing ROOT file [20].
  - In ROOT macros or compiled code, a `TFile` object can be created (opened in "RECREATE", "UPDATE", "READ" modes, etc.), and then the `Write()` method of each object (like `TH1`, `TTree`) can be called to write them to the file, and finally, the `TFile` object can be closed. For example, the `example/Macros/RIDF2Tree.C` macro demonstrates how to fill decoded data into TTree and save it to a ROOT file [4].
- **Saving in Other Formats:**
  - **Text Files:** For some simple list data, parameter settings, fitting results, etc., the C++ file output stream (`std::ofstream`) can be used to save them as text files (like `.txt`, `.csv`). This might be more convenient for exchanging data with other non-ROOT-based software, or for simple table processing.
  - **Image Files:** The images on the ROOT canvas (`TCanvas`) can be directly saved as image files in various formats (like `.png`, `.jpg`, `.pdf`, `.eps`), through the "File -> Save As..." option in the canvas menu, or by calling `TCanvas::SaveAs("filename.png")` and similar methods in the code.
  - **Custom Objects:** If users create custom C++ class objects in the analysis, and these classes inherit from `TObject` and correctly implement the related I/O methods (usually assisted by ROOT's `ClassDef` and `ClassImp` macros and dictionary generation), then these custom objects can also be saved to ROOT files like standard ROOT objects.

The choice of the appropriate saving format depends on the type of results and their subsequent use. The ROOT file format, due to its good support for complex data structures and large volumes of data, is the most commonly used archiving format in high-energy and nuclear physics experimental data analysis.

### 9. Advanced Topics and Tips

After mastering the basic operations of ANAROOT and the data analysis methods for specific detectors, this section introduces some advanced usage tips, including online data analysis, the preliminary concept of multi-detector joint analysis, and some suggestions on performance optimization and debugging.

#### 9.1 Online Data Analysis

[1, 4] ANAROOT supports not only offline data processing but also powerful online data analysis capabilities, which are crucial for real-time monitoring of the experiment, data quality checks, and rapid physical feedback.

- **Data Sources:** ANAROOT can directly connect to the online data streams produced by the RIBF DAQ system. This is typically achieved by reading data from shared memory or obtaining data from a data streaming server [1, 4]. In the CUI, this is done using the `push(0)` (or other shared memory IDs) command to connect to the shared memory data source [4].
- **Application of `AnaLoop`:** The `AnaLoop` framework is central to implementing online monitoring. Users can implement quick processing for each online event in the `Calculate()` method of `AnaLoop`, such as filling histograms of key physical quantities, checking detector count rates, monitoring trigger conditions, etc. [2]. These histograms can be dynamically updated and displayed during the analysis, providing real-time visual feedback to the experimenters.
- **Distributed Online Computing:** For experiments with high data rates or heavy online analysis tasks, RIBF adopts a distributed online computing architecture [1]. This architecture typically includes `babild` (Event Building Server) and `babian` (Online Analysis Server). Multiple desktop PCs can run ANAROOT instances, each connecting to the `babian` server to obtain data and perform parallel processing. This distributed design not only enhances the processing capability of online analysis but also increases the stability of the system, as the failure of a single analysis node does not affect the main DAQ system or other analysis nodes [1]. This architecture is key to ensuring effective online monitoring and data quality control for large-scale experiments.

#### 9.2 Preliminary Joint Analysis of Multi-Detector

Modern nuclear physics experiments often involve multiple sub-detector systems that record information about the same physical event from different angles and aspects. To fully understand and reconstruct the physical event, it is often necessary to correlate and jointly analyze the information from different detectors.

- **Basics of Data Integration:** The `TArtStoreManager` in ANAROOT plays a key role here. During the processing cycle of an event (e.g., in the `TArtAnaLoop::Calculate()` method), `TArtStoreManager` allows user code to access all registered detector data containers in the current event [5, 8]. This means the analysis code can access tracking information from SAMURAI PDC, neutron information from NEBULA, incident particle identification information from BigRIPS (if relevant data streams are merged or accessible), etc., simultaneously.
- **Event Matching and Correlation:** The prerequisite for joint analysis is the correct matching of signals from different detectors that belong to the same physical event. This is usually achieved based on event numbers or high-precision timestamps. The event building mechanism of ANAROOT, especially the `babild` in online analysis, handles the event alignment of the raw data.
- **Analysis Examples:**
  - **Gate Condition Setting:** One detector's information can be used as a gate condition to select data from another detector. For example, analyzing NEBULA neutron data selectively based on the particle species identified by BigRIPS PPACs; or studying the properties of emitted neutrons in coincidence with the charge particle track features (like momentum, scattering angle) reconstructed from SAMURAI PDC.
  - **Kinematic Reconstruction:** In some reaction channels, the complete kinematic reconstruction can be performed by measuring the momentum vectors of all final state particles (e.g., using PDC for charged particles, NEBULA for neutrons), calculating the Q-value of the reaction, invariant mass, missing mass, etc.
  - **Coincidence Measurement:** Studying the coincidence relationships between different particles, like proton-neutron, $\gamma$-neutron, etc., is crucial for understanding reaction mechanisms and nuclear structure characteristics.

Although this guide does not delve into the specific implementations of complex multi-detector joint analyses (which usually highly depend on the specific physics goals and experimental setups), users should be aware that the architecture of ANAROOT provides the fundamental data access and management capabilities for such analyses.

#### 9.3 ANAROOT Performance Optimization and Debugging Tips

When dealing with large volumes of experimental data, the execution efficiency and correctness of the analysis code are crucial.

- **Performance Optimization Recommendations:**
  - **Avoid frequent creation and destruction of objects in the event loop (`Calculate()` method):** Constructing and destructing objects are relatively time-consuming operations. It is recommended to create the necessary objects (like histograms, auxiliary calculation class instances) in the `Construct()` method, and reuse them in the `Calculate()` method.
  - **Efficient use of ROOT containers:** For `TClonesArray` and similar containers, use `GetEntriesFast()` instead of `GetEntries()` (if strict validity checks of objects are not required), and directly get object pointers via `At(i)` to avoid unnecessary copies.
  - **Reduce unnecessary calculations:** Carefully review the analysis logic to avoid recalculating quantities that do not change with each event in the loop.
  - **Choose appropriate data structures:** Select suitable data structures (like `std::vector` vs `std::map`) based on the access patterns.
  - **Compiler optimizations:** Use compiler optimization options (like `-O2` or `-O3`) when compiling user `AnaLoop` or the entire ANAROOT, but this may increase the compilation time and make debugging more difficult.
  - **Watch for I/O bottlenecks:** If the analysis speed is limited by data reading, consider using faster storage devices, or optimizing the data reading pattern (like adjusting the TTree cache size). RIBF has even explored using FPGA for hardware acceleration to improve the throughput of specific analysis tasks (like PID) [11], reflecting the demand for high-performance processing.
- **Debugging Techniques:**
  - **Print information:** Inserting print statements (like `std::cout`, `printf`, or ANAROOT provided log tools like `TArtCore::Info`, `TArtCore::Warning`, `TArtCore::Error`) at critical points in the code to output variable values or program flow information is a simple and effective debugging method.
  - **Use a debugger:** Utilize GDB (GNU Debugger) or ROOT's built-in CINT/Cling debugging features to step through the code, inspect variables, set breakpoints.
  - **Modular testing:** Break down complex analysis logic into small, independently testable modules or functions, and verify their correctness separately.
  - **Check parameter files:** Many issues arise from incorrect configuration in parameter files (XML). Carefully check that parameter names, values, and types are correct.
  - **Test with small datasets:** Initially test and debug the analysis code on a small-scale dataset with well-defined features, and once the basic logic is confirmed to be correct, expand to the full dataset.
  - **Utilize ANAROOT's diagnostic information:** Pay attention to the warnings and error messages output by ANAROOT during operation, as they often indicate where the problem lies.
  - **Version control:** Use version control systems like Git to manage analysis code, making it easier to track changes, roll back issues, and collaborate.

For complex performance issues or hard-to-locate bugs, more specialized profiling tools or a deeper understanding of the internal workings of ANAROOT and ROOT may be required.

---

## Part IV: Appendices

### A. Commonly Used ANAROOT Class Reference Summary

This appendix aims to provide a quick reference for the core classes of ANAROOT, summarizing their main functions and common methods. For detailed information, please refer to the official ANAROOT documentation or the relevant header files.

- **`TArtStoreManager`:**
  - **Function:** Central manager for data and parameters.
  - **Common Methods:**
    - `static TArtStoreManager* Instance()`: Get the globally unique instance of `TArtStoreManager`.
    - `TClonesArray* FindDataContainer(const char* name)`: Find and return a data container (usually a `TClonesArray`) by name.
    - `TArtRawSegmentObject* FindSegment(Int_t dev, Int_t fp, Int_t det)`: (If available) Find a specific raw data segment.
    - `void Register(const char* name, TObject* obj)`: (Internal use) Register a data container or parameter.
    - `TArtParam* FindParameter(const char* name)`: Find a parameter object.
- **`TArtEventStore`:**
  - **Function:** RIDF data decoding and event loop control.
  - **Common Methods:**
    - `Bool_t Open(const char* filename)`: Open an RIDF file.
    - `Bool_t Open(Int_t shm_id)`: Connect to shared memory.
    - `Bool_t GetNextEvent()`: Read and decode the next event.
    - `void ClearData()`: Clear the decoded data of the current event.
    - `TArtRawEventObject* GetRawEventObject()`: Get the raw data object of the current event.
    - `void LoadMapConfig(const char* mapfilename)`: Load ANAPAW-style mapping files.
- **`TArtRawEventObject`:**
  - **Function:** Stores decoded raw data of the entire event.
  - **Common Methods:**
    - `Int_t GetNumSegment()`: Get the number of data segments.
    - `TArtRawSegmentObject* GetSegment(Int_t i)`: Get the segment at the specified index.
    - `Int_t GetRunNumber()`, `Int_t GetEventNumber()`: Get the run and event numbers.
- **`TArtRawSegmentObject`:**
  - **Function:** Stores raw data of specific device segments.
  - **Common Methods:**
    - `Int_t GetNumData()`: Get the number of raw data objects.
    - `TArtRawDataObject* GetData(Int_t i)`: Get the data object at the specified index.
    - `Int_t GetDevice()`, `Int_t GetFocalPlane()`, `Int_t GetDetector()`: Get device, focal plane, and detector IDs.
- **`TArtRawDataObject`:**
  - **Function:** Stores the lowest level raw data unit (e.g., single ADC/TDC value).
  - **Common Methods:**
    - `Int_t GetValue()`: Get the raw value.
    - `Int_t GetGeo()`, `Int_t GetCh()`: Get the geographical address and channel number.
    - `Int_t GetCategoryID()`, `Int_t GetDetectorID()`, `Int_t GetDatatypeID()`: (Used with MapConfig) Get category, detector, and data type IDs.
- **`TArtAnaLoop` (Base Class):**
  - **Function:** Base class for user analysis loops.
  - **Methods to Override:** `Construct()`, `Calculate()`, `Destruct()`, `ClassName()`.
- **Detector Data Classes (e.g., `TArtPPAC`, `TArtDCHit`, `TArtDCTrack`, `TArtNEBULAPla`):**
  - **Function:** Store calibrated or reconstructed data for specific detectors.
  - **Common Methods:** Usually include a series of `GetXXX()` methods to access specific physical quantities (like position, time, energy, angle, momentum, etc.), the actual method names should be checked in the corresponding class header files. For example, `TArtPPAC::GetX()`, `TArtNEBULAPla::GetTime()`, `TArtDCTrack::GetMomentum()` (these are inferred based on common naming conventions, actual names may vary).

### B. XML Parameter File Examples (PDC, NEBULA)

ANAROOT uses XML files to manage parameters. Here are schematic examples of the parameter file structures for PDC (Drift Chamber) and NEBULA, the specific tags and hierarchy should refer to the actual ANAROOT module definitions.

**PDC (Drift Chamber) Parameter File Example (`SAMURAIFDC.xml` - Conceptual)**

```xml
<SAMURAIFDCParameters>
    <Detector name="FDC1">
        <Layer id="0">
            <Wire id="0">
                <T0Offset>123.4</T0Offset>
                <TDCoeff a="0.05" b="-1.2" c="15.0"/>
                <Position x="100.0" y="0.0" z="1500.0"/>
                <Resolution>0.2</Resolution>
            </Wire>
        </Layer>
        <Alignment dx="0.1" dy="-0.05" dz="0.0" rx="0.001" ry="0.0" rz="-0.0005"/>
    </Detector>
</SAMURAIFDCParameters>
```

**NEBULA Parameter File Example (`NEBULA.xml` - Conceptual)**

```xml
<NEBULAParameters>
    <Global>
        <TimeZeroOffsetGlobal>-5.6</TimeZeroOffsetGlobal>
        <PSDCutNeutronMin>0.8</PSDCutNeutronMin>
        <PSDCutNeutronMax>1.5</PSDCutNeutronMax>
    </Global>
    <Bar id="1">
        <PMT id="0"> <TDCToNsSlope>0.025</TDCToNsSlope>
            <TDCToNsOffset>-10.2</TDCToNsOffset>
            <QDCToMeVeeSlope>0.1</QDCToMeVeeSlope>
            <WalkCoeffA>50.0</WalkCoeffA>
            <WalkCoeffB>-0.5</WalkCoeffB>
        </PMT>
        <PMT id="1"> </PMT>
        <PositionCalibVeff>150.0</PositionCalibVeff> <PositionCalibOffset>0.0</PositionCalibOffset> <EnergyCalibNonLinearA>...</EnergyCalibNonLinearA>
    </Bar>
</NEBULAParameters>
```

**Note:** The above XML structures are purely illustrative examples, the actual XML tags and hierarchical structure used in ANAROOT may vary. Users need to refer to the parameter file format expected by the specific ANAROOT version and analysis modules they are using. A more general `TArtUserParameters` XML parsing code snippet is provided in [9], showing a structure like `<parameter><NAME>...</NAME><val>...</val><type>...</type></parameter>`.



### 推荐学习资源与链接

- **ANAROOT官方文档 (RIBFDAQ Wiki):**
  - ANAROOT主页: `https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT` [3]
  - 安装指南: `https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FInstallation` [2]
  - 概要 (Abstract): `https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FAbstract` [5]
  - 教程 (Tutorial): `https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FTutorial` [4]
  - (可能存在的) Kondo-san维护的ANAROOT手册页面 (部分链接可能已失效或需要内部访问权限):
    - `http://be.nucl.ap.titech.ac.jp/~kondo/moin/moin.cgi/ANAROOT/Manual` [20, 19] (包含 `analoop`, `reference` 等子页面)
- **ROOT框架官方网站:**
  - 主页与文档: `https://root.cern/` [2]
  - ROOT初学者指南: `https://root.cern.ch/root/htmldoc/guides/primer/ROOTPrimer.html` [21, 22]
  - 直方图教程: `https://root.cern/doc/master/group__tutorial__hist.html` [23, 24]
- **相关出版物与学位论文:**
  - 提及ANAROOT或其组件用于数据分析的RIBF实验相关的博士论文或会议文集，例如涉及SAMURAI和NEBULA的实验 [14, 16, 15, 25, 26]。这些文献通常会包含特定分析步骤的细节。
- **RIBF内部资源与联系人:**
  - 对于在RIKEN工作的用户，可以咨询有经验的同事、导师或ANAROOT开发/维护团队成员 (如T. Isobe [3])。

---

**结论**

ANAROOT作为RIKEN RIBF实验数据分析的核心软件框架，为用户提供了从原始数据解码到最终物理结果提取的完整工具链。它基于成熟的ROOT框架构建，并针对RIBF特有的数据格式 (RIDF) 和复杂的探测器系统（如BigRIPS, SAMURAI, NEBULA, EURICA等）进行了深度优化和功能扩展。

本指南详细介绍了ANAROOT的背景、安装配置、核心概念、数据处理流程、关键类库以及脚本编写方法。特别强调了SAMURAI实验中漂移室 (PDC/DC) 和NEBULA中子探测器的数据分析流程，包括必要的刻度步骤（如漂移室的t-d关系、NEBULA的时间、位置和能量刻度、脉冲形状甄别、串扰修正等）、数据对象的访问、以及重建物理量（如径迹、动量、中子能量）的方法。同时，本指南明确澄清了BigRIPS焦平面PPACs与SAMURAI PDC/DC在功能和分析方法上的区别，前者主要用于入射束流的粒子鉴别，后者则用于反应产物的动量分析。

通过学习和实践本指南提供的内容，用户应能：
1.  成功安装和配置ANAROOT分析环境。
2.  理解ANAROOT的基本架构和数据流。
3.  掌握使用 `TArtAnaLoop` 和 `Anafile` 进行自定义分析的方法。
4.  熟悉ANAROOT的命令行界面和常用的分析控制命令。
5.  具体应用ANAROOT分析SAMURAI PDC/DC和NEBULA探测器的数据，包括执行关键的刻度、重建和粒子鉴别步骤。
6.  利用ROOT工具对分析结果进行可视化和保存。

ANAROOT是一个持续发展的项目，其功能和模块会随着RIBF实验的进展而不断完善和更新。建议用户关注RIBFDAQ网站发布的最新信息和文档，并积极参与用户社区的交流，以便更高效地利用ANAROOT进行前沿的核物理研究。从入门到精通ANAROOT需要理论学习和大量的实践操作，希望本指南能为用户在这一过程中提供坚实的基础和有力的支持。

---

**参考文献** 


[1] ANAROOT相关网页，例如教程、概述页面。https://ribf.riken.jp/RIBFDAQ/index.php?plugin=attach&refer=Tools%2FAnalysis%2FANAROOT&openfile=anaroot_ribfusermeeting2013.pdf

[2] ANAROOT安装指南页面。https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FInstallation

[3] ANAROOT主页或开发者信息。https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT

[4] ANAROOT教程页面。https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FTutorial


[5] ANAROOT概述 (Abstract) 页面。https://ribf.riken.jp/RIBFDAQ/index.php?Tools%2FAnalysis%2FANAROOT%2FAbstract

[6] GitHub或其他代码托管平台 (作为源码获取的辅助途径)。https://docs.github.com/en/repositories/working-with-files/using-files/downloading-source-code-archives

[7] 同[6]。https://docs.github.com/enterprise-cloud@latest/repositories/working-with-files/using-files/downloading-source-code-archives

[8] ANAROOT内部类文档或头文件注释 (例如 `TArtStoreManager.hh`, `TArtRawEventObject.hh` 等)。

[9] ANAROOT关于参数管理 (如 `TArtUserParameters`, `TArtSAMURAIParameters`) 的设计文档或示例。

[10] ANAROOT关于 `TArtAnaLoop` 和 `Anafile` 使用的文档或示例 (如 `TAlEncExample` 相关)。http://be.nucl.ap.titech.ac.jp/~kondo/moin/moin.cgi/ANAROOT/Manual/analoop

[11] BigRIPS谱仪相关的技术文档或出版物。https://inis.iaea.org/records/w1kc8-5ep03/files/53109350.pdf?download=1

[12] SAMURAI谱仪相关的技术文档或出版物。https://www.nishina.riken.jp/ribf/SAMURAI/overview.html

[13] 同[12]。https://ribf.riken.jp/SAMURAI/120425_SAMURAIConstProp.pdf

[14] 涉及SAMURAI PDC和NEBULA数据分析的博士论文或详细技术报告 (例如，提及MDF方法、串扰修正算法等)。https://tuprints.ulb.tu-darmstadt.de/20267/1/Dissertation_LehrChristopher_2022-01-04.pdf

[15] 卡尔曼滤波在径迹重建中应用的通用文献或特定于ANAROOT/SAMURAI的实现说明。https://www.nishina.riken.jp/researcher/APR/APR049/pdf/161.pdf

[16] NEBULA探测器相关的技术文档或出版物。https://www.nishina.riken.jp/researcher/APR/APR056/pdf/91.pdf

[17] NEBULA探测器 (包括NEBULA-Plus) 的设计、性能和刻度相关的出版物。https://indico.cern.ch/event/865322/contributions/5048179/attachments/2512879/4319595/2022-02-21%20Neutron%20detectors%20v6.pdf

[18] 关于塑料闪烁体中子/伽马甄别 (PSD) 的通用原理或特定于NEBULA的文献。https://inis.iaea.org/collection/NCLCollectionStore/_Public/55/078/55078687.pdf

[19] Kondo-san维护的ANAROOT手册页面中关于 `analoop` 和 `reference` 的部分。http://be.nucl.ap.titech.ac.jp/~kondo/moin/moin.cgi/ANAROOT/Manual/analoop

[20] Kondo-san维护的ANAROOT手册页面中关于CUI命令的部分。http://be.nucl.ap.titech.ac.jp/~kondo/moin/moin.cgi/ANAROOT/Manual/reference

[21] ROOT初学者指南。https://root.cern.ch/root/htmldoc/guides/primer/ROOTPrimer.html

[22] 同[21]。https://www.ao-universe.com/guides/classic-ao/gameplay-guides-6/introduction-to-scripting

[23] ROOT直方图教程。https://root.cern/doc/master/group__tutorial__hist.html

[24] 同[23]。https://root.cern/manual/histograms/

[25] 其他使用ANAROOT进行数据分析的RIBF实验的出版物。https://tuprints.ulb.tu-darmstadt.de/9192/7/PhD_thesis_JKahlbow.pdf

[26] 同[25]。https://indico.global/event/6805/contributions/58357/attachments/29459/52337/OS_day2_id48_ichinohe.pdf